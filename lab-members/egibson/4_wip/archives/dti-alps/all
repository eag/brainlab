#!/bin/bash -eux

readonly INPUT_DIR="/net/synapse/nt/data/BCSA1F/MRI/processed/DTI-ALPS/computebrain"
readonly OUTPUT_DIR="/net/synapse/nt/data/BCSA1F/MRI/processed/DTI-ALPS/TBSS"

find_sessions () {
	# set the pattern to find the directories we care about
	if [[ "$#" -eq 0 ]]
	then
		local pattern="*"
	else
		local pattern=".*("
		for num; do
			pattern="${pattern}${num}|"
		done
		pattern="${pattern:0:-1}).*"	# cut the last pipe
	fi

	find "${INPUT_DIR}" -maxdepth 1 -mindepth 1 -type d -regextype posix-extended -regex "${pattern}"
}

function process_session {
	local session_path=$1
	local session_name=$(basename $session_path)
	local subject_dir=$(dirname $session_path)

	echo $session_path
	echo $session_name
	echo $subject_dir
	

	
	export HDF5_USE_FILE_LOCKING=FALSE

	# copy the FA from computebrain output into TBSS directory
	cp ${INPUT_DIR}/${session_name}/dwipreprocessed/regrid_1.25/dwi_denoised_degibbs_preproc_clean_N4_1.25regrid_FA.nii ${OUTPUT_DIR}/${session_name}_FA.nii
	gzip ${OUTPUT_DIR}/${session_name}_FA.nii

	# make directory for the non-FA images (i.e. tensor)
	mkdir ${OUTPUT_DIR}/tensor || true

	# copy over tensor from computebrain output, renames to having same naming as corresponding FA (NOTE: the tensor WILL get relabelled as FA, this is not a mistake, just a requirement for the function)
	cp ${INPUT_DIR}/${session_name}/dwipreprocessed/regrid_1.25/dwi_denoised_degibbs_preproc_clean_N4_1.25regrid_tensor.nii ${OUTPUT_DIR}/tensor/${session_name}_FA.nii
	gzip ${OUTPUT_DIR}/tensor/${session_name}_FA.nii


}

sessions=( $(find_sessions $@) )

for session in ${sessions[@]}; do
	echo $session
    process_session $session
done


# TBSS Step 1: erode your FA images slightly and zero the end slices and move these images to a “FA” subdirectory
fsl5.0-tbss_1_preproc *.nii.gz

# TBSS Step 2: runs the nonlinear registration, aligning all FA images to a 1x1x1mm standard space, the -T tage indicates we will be using the FMRIB58_FA_1mm as the target template in fsl
fsl5.0-tbss_2_reg -T 

# TBSS Step 3: Applies the nonlinear transforms found in the previous stage to all subjects to bring them into standard space, also creates files called “mean_FA” and “mean_FA_skeleton” based on the mean of all of the subjects
fsl5.0-tbss_3_postreg -S

# TBSS Step 4: Thresholds the mean FA skeleton image, our chosen value is 0.2
fsl5.0-tbss_4_prestats 0.2

# TBSS Step 5: run TBSS for the non-FA image for all subjects and moving output into the tensor directory
fsl5.0-tbss_non_FA tensor


#!/bin/bash -eux

readonly INPUT_DIR="/net/synapse/nt/data/BCSA1F/MRI/processed/DTI-ALPS/computebrain"
readonly OUTPUT_DIR="/net/synapse/nt/data/BCSA1F/MRI/processed/DTI-ALPS/TBSS"

find_sessions () {
	# set the pattern to find the directories we care about
	if [[ "$#" -eq 0 ]]
	then
		local pattern="*"
	else
		local pattern=".*("
		for num; do
			pattern="${pattern}${num}|"
		done
		pattern="${pattern:0:-1}).*"	# cut the last pipe
	fi

	find "${INPUT_DIR}" -maxdepth 1 -mindepth 1 -type d -regextype posix-extended -regex "${pattern}"
}

function process_session {
	local session_path=$1
	local session_name=$(basename $session_path)
	local subject_dir=$(dirname $session_path)

	echo $session_path
	echo $session_name
	echo $subject_dir


	# moving TBSS non-FA output into the tensor directory
	mkdir ${OUTPUT_DIR}/tensor/origal_data || true
	mv ${OUTPUT_DIR}/tensor/${session_name}_FA.nii.gz ${OUTPUT_DIR}/tensor/origal_data/${session_name}_tensor.nii.gz

	mkdir ${OUTPUT_DIR}/tensor/${session_name}

	mv ${OUTPUT_DIR}/FA/${session_name}_FA_to_target_tensor.nii.gz ${OUTPUT_DIR}/tensor/${session_name}/

	# separating out the 4D tensor image to their individual tensors and renaming
	ImageMath 4 ${OUTPUT_DIR}/tensor/${session_name}/${session_name}_tensor_comp.nii.gz TimeSeriesDisassemble ${OUTPUT_DIR}/tensor/${session_name}/${session_name}_FA_to_target_tensor.nii.gz
	i=0 
	for index in xx xy xz yy yz zz; do
		mv ${OUTPUT_DIR}/tensor/${session_name}/${session_name}_tensor_comp100${i}.nii.gz ${OUTPUT_DIR}/tensor/${session_name}/${session_name}_tensor_comp_D${index}.nii.gz
		i=$((i+1))
	done


}

sessions=( $(find_sessions $@) )

for session in ${sessions[@]}; do
	echo $session
    process_session $session
done


#!/bin/bash -eux

readonly INPUT_DIR="/net/synapse/nt/data/BCSA1F/MRI/processed/DTI-ALPS/TBSS/tensor"

find_sessions () {
	# set the pattern to find the directories we care about
	if [[ "$#" -eq 0 ]]
	then
		local pattern="*"
	else
		local pattern=".*("
		for num; do
			pattern="${pattern}${num}|"
		done
		pattern="${pattern:0:-1}).*"	# cut the last pipe
	fi

	find "${INPUT_DIR}" -maxdepth 1 -mindepth 1 -type d -regextype posix-extended -regex "${pattern}"
}


function process_session {
	local session_path=$1
	local session_name=$(basename $session_path)
	local subject_dir=$(dirname $session_path)

	echo $session_path
	echo $session_name
	echo $subject_dir
	
	export HDF5_USE_FILE_LOCKING=FALSE

	# generating all the diffusion values needed for the DTI-ALPS calculation and storing into variables
	L_Hemi_Dxproj=$(fsl5.0-fslstats ${INPUT_DIR}/${session_name}/${session_name}_tensor_comp_Dxx.nii.gz -k L_hemi_proj.nii.gz -m)
	L_Hemi_Dxassoc=$(fsl5.0-fslstats ${INPUT_DIR}/${session_name}/${session_name}_tensor_comp_Dxx.nii.gz -k L_hemi_assoc.nii.gz -m)
	L_Hemi_Dyproj=$(fsl5.0-fslstats ${INPUT_DIR}/${session_name}/${session_name}_tensor_comp_Dyy.nii.gz -k L_hemi_proj.nii.gz -m)
	L_Hemi_Dzassoc=$(fsl5.0-fslstats ${INPUT_DIR}/${session_name}/${session_name}_tensor_comp_Dzz.nii.gz -k L_hemi_assoc.nii.gz -m)
	R_Hemi_Dxproj=$(fsl5.0-fslstats ${INPUT_DIR}/${session_name}/${session_name}_tensor_comp_Dxx.nii.gz -k R_hemi_proj.nii.gz -m)
	R_Hemi_Dxassoc=$(fsl5.0-fslstats ${INPUT_DIR}/${session_name}/${session_name}_tensor_comp_Dxx.nii.gz -k R_hemi_assoc.nii.gz -m)
	R_Hemi_Dyproj=$(fsl5.0-fslstats ${INPUT_DIR}/${session_name}/${session_name}_tensor_comp_Dyy.nii.gz -k R_hemi_proj.nii.gz -m)
	R_Hemi_Dzassoc=$(fsl5.0-fslstats ${INPUT_DIR}/${session_name}/${session_name}_tensor_comp_Dzz.nii.gz -k R_hemi_assoc.nii.gz -m)

	# using the diffusion values to calculate the ALPS Index
	# L_Hemi_ALPS_Index=$(((${L_Hemi_Dxproj}*${L_Hemi_Dxassoc})/2)/((${L_Hemi_Dyproj}*${L_Hemi_Dzassoc})/2))
	# R_Hemi_ALPS_Index=$(((${R_Hemi_Dxproj}*${R_Hemi_Dxassoc})/2)/((${R_Hemi_Dyproj}*${R_Hemi_Dzassoc})/2))

	echo Subject, L_Hemi_Dxproj, L_Hemi_Dxassoc, L_Hemi_Dyproj, L_Hemi_Dzassoc, R_Hemi_Dxproj, R_Hemi_Dxassoc, R_Hemi_Dyproj, R_Hemi_Dzassoc > ${INPUT_DIR}/${session_name}/${session_name}_DTI-ALPS_volumetrics.csv
	echo ${session_name}, ${L_Hemi_Dxproj}, ${L_Hemi_Dxassoc}, ${L_Hemi_Dyproj}, ${L_Hemi_Dzassoc}, ${R_Hemi_Dxproj}, ${R_Hemi_Dxassoc}, ${R_Hemi_Dyproj}, ${R_Hemi_Dzassoc} >> ${INPUT_DIR}/${session_name}/${session_name}_DTI-ALPS_volumetrics.csv

	echo ${session_name}, ${L_Hemi_Dxproj}, ${L_Hemi_Dxassoc}, ${L_Hemi_Dyproj}, ${L_Hemi_Dzassoc}, ${R_Hemi_Dxproj}, ${R_Hemi_Dxassoc}, ${R_Hemi_Dyproj}, ${R_Hemi_Dzassoc} >> ${INPUT_DIR}/PSCS1F_DTI-ALPS_volumetrics.csv

	
}

sessions=( $(find_sessions $@) )

for session in ${sessions[@]}; do
	echo $session
    process_session $session
done
